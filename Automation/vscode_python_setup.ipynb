{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1984a8",
   "metadata": {},
   "source": [
    "# Auto install python libraries for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c7c68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_libs(packages):\n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package[\"import_name\"])\n",
    "            print(f\"‚úÖ {package['name']} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"‚¨áÔ∏è Installing {package['name']}...\")\n",
    "\n",
    "            # ‚úÖ Handle both string and list pip_name\n",
    "            pip_args = package[\"pip_name\"]\n",
    "            if isinstance(pip_args, str):\n",
    "                pip_args = [pip_args]\n",
    "\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pip_args])\n",
    "                print(f\"‚úÖ {package['name']} installed\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Failed to install {package['name']}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bb83c",
   "metadata": {},
   "source": [
    "# Mac specific pre-setup by installing require brew packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def is_brew_available():\n",
    "    return shutil.which(\"brew\") is not None\n",
    "\n",
    "def is_package_installed(package):\n",
    "    result = subprocess.run([\"brew\", \"list\", \"--formula\", package], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    return result.returncode == 0\n",
    "\n",
    "def brew_install(packages):\n",
    "    if not is_brew_available():\n",
    "        print(\"‚ùå Homebrew is not available in PATH.\")\n",
    "        return\n",
    "\n",
    "    for package in packages:\n",
    "        if is_package_installed(package):\n",
    "            print(f\"‚úÖ {package} is already installed.\")\n",
    "        else:\n",
    "            print(f\"‚¨áÔ∏è Installing {package}...\")\n",
    "            try:\n",
    "                subprocess.check_call([\"brew\", \"install\", package])\n",
    "                print(f\"‚úÖ {package} installed successfully.\\n\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Failed to install {package}: {e}\\n\")\n",
    "\n",
    "# brew packages to install\n",
    "libs = [\"unixodbc\", # ODBC driver for Snowflake\n",
    "        \"snowflake\", # Snowflake CLI\n",
    "        \"libomp\", # OpenMP support for XGBoost & LightGBM\n",
    "        'cmake', # CMake build system\n",
    "        \"llvm\", # Modern compiler toolchain used by some ML libraries\n",
    "        'openssl@3', # OpenSSL 3.x for compatibility\n",
    "        ]\n",
    "\n",
    "brew_install(libs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da0075",
   "metadata": {},
   "source": [
    "## 1. Data Wraggling Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027c652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = [\n",
    "    # ‚úÖ Data Wrangling\n",
    "    {\"name\": \"Pandas\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"Polars\", \"pip_name\": \"polars\", \"import_name\": \"polars\"},\n",
    "    {\"name\": \"Dask\", \"pip_name\": \"dask[dataframe]\", \"import_name\": \"dask\"},\n",
    "    {\"name\": \"PyArrow\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow\"},\n",
    "    {\"name\": \"PyTables\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "    {\"name\": \"Feather\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow.feather\"},\n",
    "    {\"name\": \"Parquet\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow.parquet\"},\n",
    "    {\"name\": \"HDF5\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "    {\"name\": \"CSV\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"JSON\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"Excel\", \"pip_name\": \"openpyxl\", \"import_name\": \"openpyxl\"},\n",
    "    {\"name\": \"HDF5\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "]\n",
    "\n",
    "install_libs(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c3aab",
   "metadata": {},
   "source": [
    "## 2. Data Connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072d7829",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = [# üîå Data Connections ‚Äì Databases\n",
    "    {\"name\": \"SQLAlchemy\", \"pip_name\": \"sqlalchemy\", \"import_name\": \"sqlalchemy\"},\n",
    "    {\"name\": \"PyODBC\", \"pip_name\": \"pyodbc\", \"import_name\": \"pyodbc\"},\n",
    "    {\"name\": \"psycopg2 (PostgreSQL)\", \"pip_name\": \"psycopg2-binary\", \"import_name\": \"psycopg2\"},\n",
    "    {\"name\": \"MySQL Connector\", \"pip_name\": \"mysql-connector-python\", \"import_name\": \"mysql.connector\"},\n",
    "    {\"name\": \"MongoDB\", \"pip_name\": \"pymongo\", \"import_name\": \"pymongo\"},\n",
    "    {\"name\": \"SQLite\", \"pip_name\": \"sqlite3\", \"import_name\": \"sqlite3\"},\n",
    "\n",
    "    # üîå Data Connections ‚Äì Cloud\n",
    "    {\"name\": \"Snowflake Connector\", \"pip_name\": \"snowflake-connector-python\", \"import_name\": \"snowflake.connector\"},\n",
    "    {\"name\": \"Google BigQuery\", \"pip_name\": \"google-cloud-bigquery\", \"import_name\": \"google.cloud.bigquery\"},\n",
    "    {\"name\": \"AWS SDK (boto3)\", \"pip_name\": \"boto3\", \"import_name\": \"boto3\"},\n",
    "    {\"name\": \"Azure SDK\", \"pip_name\": \"azure-storage-blob\", \"import_name\": \"azure.storage.blob\"},\n",
    "    {\"name\": \"Databricks SQL Connector\", \"pip_name\": \"databricks-sql-connector\", \"import_name\": \"databricks.sql\"},\n",
    "    {\"name\": \"Apache Kafka\", \"pip_name\": \"kafka-python\", \"import_name\": \"kafka\"},\n",
    "\n",
    "    # üìÇ Microsoft SharePoint (via Office365 REST API)\n",
    "    {\"name\": \"Office365-REST-Python-Client\", \"pip_name\": \"Office365-REST-Python-Client\", \"import_name\": \"office365.sharepoint.client_context\"},\n",
    "\n",
    "    # üìä Tableau / Power BI Integration\n",
    "    {\"name\": \"Tableau Hyper API\", \"pip_name\": \"tableauhyperapi\", \"import_name\": \"tableauhyperapi\"},\n",
    "    {\"name\": \"Power BI REST Client\", \"pip_name\": \"powerbiclient\", \"import_name\": \"powerbiclient\"},\n",
    "\n",
    "    # üåê API Libraries\n",
    "    {\"name\": \"Requests\", \"pip_name\": \"requests\", \"import_name\": \"requests\"},\n",
    "    {\"name\": \"HTTPX\", \"pip_name\": \"httpx\", \"import_name\": \"httpx\"},\n",
    "    {\"name\": \"FastAPI\", \"pip_name\": \"fastapi\", \"import_name\": \"fastapi\"},\n",
    "    {\"name\": \"Uvicorn (for FastAPI)\", \"pip_name\": \"uvicorn\", \"import_name\": \"uvicorn\"},\n",
    "    {\"name\": \"Flask\", \"pip_name\": \"flask\", \"import_name\": \"flask\"},\n",
    "    {\"name\": \"Django\", \"pip_name\": \"django\", \"import_name\": \"django\"},\n",
    "    {\"name\": \"Tornado\", \"pip_name\": \"tornado\", \"import_name\": \"tornado\"},\n",
    "]\n",
    "\n",
    "install_libs(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d49061",
   "metadata": {},
   "source": [
    "## 3. Stat and Visualization Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79182f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = [\n",
    "    # üìä Statistics & Math\n",
    "    {\"name\": \"NumPy\", \"pip_name\": \"numpy\", \"import_name\": \"numpy\"},\n",
    "    {\"name\": \"SciPy\", \"pip_name\": \"scipy\", \"import_name\": \"scipy\"},\n",
    "    {\"name\": \"Statsmodels\", \"pip_name\": \"statsmodels\", \"import_name\": \"statsmodels\"},\n",
    "\n",
    "    # üìà Visualization\n",
    "    {\"name\": \"Matplotlib\", \"pip_name\": \"matplotlib\", \"import_name\": \"matplotlib\"},\n",
    "    {\"name\": \"Seaborn\", \"pip_name\": \"seaborn\", \"import_name\": \"seaborn\"},\n",
    "    {\"name\": \"Plotly\", \"pip_name\": \"plotly\", \"import_name\": \"plotly\"},\n",
    "    {\"name\": \"Altair\", \"pip_name\": \"altair\", \"import_name\": \"altair\"},\n",
    "    {\"name\": \"Bokeh\", \"pip_name\": \"bokeh\", \"import_name\": \"bokeh\"},\n",
    "    {\"name\": \"Geopandas\", \"pip_name\": \"geopandas\", \"import_name\": \"geopandas\"},\n",
    "]\n",
    "\n",
    "install_libs(sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64072369",
   "metadata": {},
   "source": [
    "## 4. ML and Other Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required packages\n",
    "import os\n",
    "os.environ[\"DYLD_LIBRARY_PATH\"] = \"/opt/homebrew/opt/libomp/lib\"\n",
    "\n",
    "ml = [\n",
    "    # ü§ñ Machine Learning\n",
    "    {\"name\": \"Scikit-learn\", \"pip_name\": \"scikit-learn\", \"import_name\": \"sklearn\"},\n",
    "    # {\"name\": \"XGBoost\", \"pip_name\": \"xgboost\", \"import_name\": \"xgboost\"},\n",
    "    # {\"name\": \"LightGBM\", \"pip_name\": \"lightgbm\", \"import_name\": \"lightgbm\"},\n",
    "    {\"name\": \"CatBoost\", \"pip_name\": \"catboost\", \"import_name\": \"catboost\"},\n",
    "    # {\"name\": \"TensorFlow\", \"pip_name\": \"tensorflow\", \"import_name\": \"tensorflow\"},\n",
    "    {\"name\": \"PyTorch\", \"pip_name\": [\"torch\", \"torchvision\", \"torchaudio\"], \"import_name\": \"torch\"},\n",
    "    {\"name\": \"Keras\", \"pip_name\": \"keras\", \"import_name\": \"keras\"},\n",
    "    {\"name\": \"Hugging Face Transformers\", \"pip_name\": \"transformers\", \"import_name\": \"transformers\"},\n",
    "    {\"name\": \"Fastai\", \"pip_name\": \"fastai\", \"import_name\": \"fastai\"},\n",
    "    {\"name\": \"TPOT\", \"pip_name\": \"tpot\", \"import_name\": \"tpot\"},\n",
    "    {\"name\": \"MLflow\", \"pip_name\": \"mlflow\", \"import_name\": \"mlflow\"},\n",
    "\n",
    "    # üß™ Notebook Environment\n",
    "    {\"name\": \"JupyterLab\", \"pip_name\": \"jupyterlab\", \"import_name\": \"jupyterlab\"},\n",
    "    {\"name\": \"Notebook\", \"pip_name\": \"notebook\", \"import_name\": \"notebook\"},\n",
    "    {\"name\": \"Voila\", \"pip_name\": \"voila\", \"import_name\": \"voila\"},\n",
    "    \n",
    "]\n",
    "\n",
    "install_libs(ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml2 = [\n",
    "    # ü§ñ Machine Learning 2\n",
    "    {\"name\": \"XGBoost\", \"pip_name\": \"xgboost\", \"import_name\": \"xgboost\"},\n",
    "    {\"name\": \"LightGBM\", \"pip_name\": \"lightgbm\", \"import_name\": \"lightgbm\"},\n",
    "    \n",
    "]\n",
    "\n",
    "install_libs(ml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall xgboost -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
