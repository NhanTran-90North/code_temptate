{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1984a8",
   "metadata": {},
   "source": [
    "# Auto install python libraries for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c7c68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_libs(packages):\n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package[\"import_name\"])\n",
    "            print(f\"âœ… {package['name']} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"â¬‡ï¸ Installing {package['name']}...\")\n",
    "\n",
    "            # âœ… Handle both string and list pip_name\n",
    "            pip_args = package[\"pip_name\"]\n",
    "            if isinstance(pip_args, str):\n",
    "                pip_args = [pip_args]\n",
    "\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pip_args])\n",
    "                print(f\"âœ… {package['name']} installed\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âŒ Failed to install {package['name']}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bb83c",
   "metadata": {},
   "source": [
    "# Mac specific pre-setup by installing require brew packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc9945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… unixodbc is already installed.\n",
      "âœ… snowflake is already installed.\n",
      "âœ… libomp is already installed.\n",
      "âœ… cmake is already installed.\n",
      "âœ… llvm is already installed.\n",
      "âœ… openssl@3 is already installed.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import platform\n",
    "\n",
    "def is_brew_available():\n",
    "    return shutil.which(\"brew\") is not None\n",
    "\n",
    "def is_package_installed(package):\n",
    "    result = subprocess.run([\"brew\", \"list\", \"--formula\", package], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    return result.returncode == 0\n",
    "\n",
    "def brew_install(packages):\n",
    "    if not is_brew_available():\n",
    "        print(\"âŒ Homebrew is not available in PATH.\")\n",
    "        return\n",
    "\n",
    "    for package in packages:\n",
    "        if is_package_installed(package):\n",
    "            print(f\"âœ… {package} is already installed.\")\n",
    "        else:\n",
    "            print(f\"â¬‡ï¸ Installing {package}...\")\n",
    "            try:\n",
    "                subprocess.check_call([\"brew\", \"install\", package])\n",
    "                print(f\"âœ… {package} installed successfully.\\n\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âŒ Failed to install {package}: {e}\\n\")\n",
    "\n",
    "# brew packages to install\n",
    "libs = [\"unixodbc\", # ODBC driver for Snowflake\n",
    "        \"snowflake\", # Snowflake CLI\n",
    "        \"libomp\", # OpenMP support for XGBoost & LightGBM\n",
    "        'cmake', # CMake build system\n",
    "        \"llvm\", # Modern compiler toolchain used by some ML libraries\n",
    "        'openssl@3', # OpenSSL 3.x for compatibility\n",
    "        ]\n",
    "\n",
    "\n",
    "# Brew install if on macOS\n",
    "if platform.system() == 'Darwin':  # macOS returns 'Darwin'\n",
    "    brew_install(libs)\n",
    "else:\n",
    "    print(\"Not on macOS, skipping brew install\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da0075",
   "metadata": {},
   "source": [
    "## 1. Data Wraggling Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e027c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pandas already installed\n",
      "âœ… Polars already installed\n",
      "âœ… Dask already installed\n",
      "âœ… PyArrow already installed\n",
      "âœ… PyTables already installed\n",
      "âœ… Feather already installed\n",
      "âœ… Parquet already installed\n",
      "âœ… HDF5 already installed\n",
      "âœ… CSV already installed\n",
      "âœ… JSON already installed\n",
      "âœ… Excel already installed\n",
      "âœ… HDF5 already installed\n"
     ]
    }
   ],
   "source": [
    "dw = [\n",
    "    # âœ… Data Wrangling\n",
    "    {\"name\": \"Pandas\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"Polars\", \"pip_name\": \"polars\", \"import_name\": \"polars\"},\n",
    "    {\"name\": \"Dask\", \"pip_name\": \"dask[dataframe]\", \"import_name\": \"dask\"},\n",
    "    {\"name\": \"PyArrow\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow\"},\n",
    "    {\"name\": \"PyTables\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "    {\"name\": \"Feather\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow.feather\"},\n",
    "    {\"name\": \"Parquet\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow.parquet\"},\n",
    "    {\"name\": \"HDF5\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "    {\"name\": \"CSV\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"JSON\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"Excel\", \"pip_name\": \"openpyxl\", \"import_name\": \"openpyxl\"},\n",
    "    {\"name\": \"HDF5\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "]\n",
    "\n",
    "install_libs(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c3aab",
   "metadata": {},
   "source": [
    "## 2. Data Connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "072d7829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SQLAlchemy already installed\n",
      "âœ… PyODBC already installed\n",
      "âœ… psycopg2 (PostgreSQL) already installed\n",
      "âœ… MySQL Connector already installed\n",
      "âœ… MongoDB already installed\n",
      "âœ… SQLite already installed\n",
      "âœ… Snowflake Connector already installed\n",
      "âœ… Google BigQuery already installed\n",
      "âœ… AWS SDK (boto3) already installed\n",
      "âœ… Azure SDK already installed\n",
      "âœ… Databricks SQL Connector already installed\n",
      "âœ… Apache Kafka already installed\n",
      "âœ… Office365-REST-Python-Client already installed\n",
      "âœ… Tableau Hyper API already installed\n",
      "âœ… Power BI REST Client already installed\n",
      "âœ… Requests already installed\n",
      "âœ… HTTPX already installed\n",
      "âœ… FastAPI already installed\n",
      "âœ… Uvicorn (for FastAPI) already installed\n",
      "âœ… Flask already installed\n",
      "âœ… Django already installed\n",
      "âœ… Tornado already installed\n"
     ]
    }
   ],
   "source": [
    "dc = [# ðŸ”Œ Data Connections â€“ Databases\n",
    "    {\"name\": \"SQLAlchemy\", \"pip_name\": \"sqlalchemy\", \"import_name\": \"sqlalchemy\"},\n",
    "    {\"name\": \"PyODBC\", \"pip_name\": \"pyodbc\", \"import_name\": \"pyodbc\"},\n",
    "    {\"name\": \"psycopg2 (PostgreSQL)\", \"pip_name\": \"psycopg2-binary\", \"import_name\": \"psycopg2\"},\n",
    "    {\"name\": \"MySQL Connector\", \"pip_name\": \"mysql-connector-python\", \"import_name\": \"mysql.connector\"},\n",
    "    {\"name\": \"MongoDB\", \"pip_name\": \"pymongo\", \"import_name\": \"pymongo\"},\n",
    "    {\"name\": \"SQLite\", \"pip_name\": \"sqlite3\", \"import_name\": \"sqlite3\"},\n",
    "\n",
    "    # ðŸ”Œ Data Connections â€“ Cloud\n",
    "    {\"name\": \"Snowflake Connector\", \"pip_name\": \"snowflake-connector-python\", \"import_name\": \"snowflake.connector\"},\n",
    "    {\"name\": \"Google BigQuery\", \"pip_name\": \"google-cloud-bigquery\", \"import_name\": \"google.cloud.bigquery\"},\n",
    "    {\"name\": \"AWS SDK (boto3)\", \"pip_name\": \"boto3\", \"import_name\": \"boto3\"},\n",
    "    {\"name\": \"Azure SDK\", \"pip_name\": \"azure-storage-blob\", \"import_name\": \"azure.storage.blob\"},\n",
    "    {\"name\": \"Databricks SQL Connector\", \"pip_name\": \"databricks-sql-connector\", \"import_name\": \"databricks.sql\"},\n",
    "    {\"name\": \"Apache Kafka\", \"pip_name\": \"kafka-python\", \"import_name\": \"kafka\"},\n",
    "\n",
    "    # ðŸ“‚ Microsoft SharePoint (via Office365 REST API)\n",
    "    {\"name\": \"Office365-REST-Python-Client\", \"pip_name\": \"Office365-REST-Python-Client\", \"import_name\": \"office365.sharepoint.client_context\"},\n",
    "\n",
    "    # ðŸ“Š Tableau / Power BI Integration\n",
    "    {\"name\": \"Tableau Hyper API\", \"pip_name\": \"tableauhyperapi\", \"import_name\": \"tableauhyperapi\"},\n",
    "    {\"name\": \"Power BI REST Client\", \"pip_name\": \"powerbiclient\", \"import_name\": \"powerbiclient\"},\n",
    "\n",
    "    # ðŸŒ API Libraries\n",
    "    {\"name\": \"Requests\", \"pip_name\": \"requests\", \"import_name\": \"requests\"},\n",
    "    {\"name\": \"HTTPX\", \"pip_name\": \"httpx\", \"import_name\": \"httpx\"},\n",
    "    {\"name\": \"FastAPI\", \"pip_name\": \"fastapi\", \"import_name\": \"fastapi\"},\n",
    "    {\"name\": \"Uvicorn (for FastAPI)\", \"pip_name\": \"uvicorn\", \"import_name\": \"uvicorn\"},\n",
    "    {\"name\": \"Flask\", \"pip_name\": \"flask\", \"import_name\": \"flask\"},\n",
    "    {\"name\": \"Django\", \"pip_name\": \"django\", \"import_name\": \"django\"},\n",
    "    {\"name\": \"Tornado\", \"pip_name\": \"tornado\", \"import_name\": \"tornado\"},\n",
    "]\n",
    "\n",
    "install_libs(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d49061",
   "metadata": {},
   "source": [
    "## 3. Stat and Visualization Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b79182f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NumPy already installed\n",
      "âœ… SciPy already installed\n",
      "âœ… Statsmodels already installed\n",
      "âœ… Matplotlib already installed\n",
      "âœ… Seaborn already installed\n",
      "âœ… Plotly already installed\n",
      "âœ… Altair already installed\n",
      "âœ… Bokeh already installed\n",
      "âœ… Geopandas already installed\n"
     ]
    }
   ],
   "source": [
    "sv = [\n",
    "    # ðŸ“Š Statistics & Math\n",
    "    {\"name\": \"NumPy\", \"pip_name\": \"numpy\", \"import_name\": \"numpy\"},\n",
    "    {\"name\": \"SciPy\", \"pip_name\": \"scipy\", \"import_name\": \"scipy\"},\n",
    "    {\"name\": \"Statsmodels\", \"pip_name\": \"statsmodels\", \"import_name\": \"statsmodels\"},\n",
    "\n",
    "    # ðŸ“ˆ Visualization\n",
    "    {\"name\": \"Matplotlib\", \"pip_name\": \"matplotlib\", \"import_name\": \"matplotlib\"},\n",
    "    {\"name\": \"Seaborn\", \"pip_name\": \"seaborn\", \"import_name\": \"seaborn\"},\n",
    "    {\"name\": \"Plotly\", \"pip_name\": \"plotly\", \"import_name\": \"plotly\"},\n",
    "    {\"name\": \"Altair\", \"pip_name\": \"altair\", \"import_name\": \"altair\"},\n",
    "    {\"name\": \"Bokeh\", \"pip_name\": \"bokeh\", \"import_name\": \"bokeh\"},\n",
    "    {\"name\": \"Geopandas\", \"pip_name\": \"geopandas\", \"import_name\": \"geopandas\"},\n",
    "]\n",
    "\n",
    "install_libs(sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64072369",
   "metadata": {},
   "source": [
    "## 4. ML and Other Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f93ba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Scikit-learn already installed\n",
      "âœ… CatBoost already installed\n",
      "âœ… Category Encoders already installed\n",
      "âœ… PyTorch already installed\n",
      "â¬‡ï¸ Installing Keras...\n",
      "Requirement already satisfied: keras in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (2.3.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from keras) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from optree->keras) (4.13.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "âœ… Keras installed\n",
      "âœ… Hugging Face Transformers already installed\n",
      "âœ… Fastai already installed\n",
      "âœ… TPOT already installed\n",
      "âœ… MLflow already installed\n",
      "âœ… JupyterLab already installed\n",
      "âœ… Notebook already installed\n",
      "âœ… Voila already installed\n"
     ]
    }
   ],
   "source": [
    "# Define required packages\n",
    "import os\n",
    "os.environ[\"DYLD_LIBRARY_PATH\"] = \"/opt/homebrew/opt/libomp/lib\"\n",
    "\n",
    "ml = [\n",
    "    # ðŸ¤– Machine Learning\n",
    "    {\"name\": \"Scikit-learn\", \"pip_name\": \"scikit-learn\", \"import_name\": \"sklearn\"},\n",
    "    # {\"name\": \"XGBoost\", \"pip_name\": \"xgboost\", \"import_name\": \"xgboost\"},\n",
    "    # {\"name\": \"LightGBM\", \"pip_name\": \"lightgbm\", \"import_name\": \"lightgbm\"},\n",
    "    {\"name\": \"CatBoost\", \"pip_name\": \"catboost\", \"import_name\": \"catboost\"},\n",
    "    {\"name\": \"Category Encoders\", \"pip_name\": \"category_encoders\", \"import_name\": \"category_encoders\"},\n",
    "    # {\"name\": \"TensorFlow\", \"pip_name\": \"tensorflow\", \"import_name\": \"tensorflow\"},\n",
    "    {\"name\": \"PyTorch\", \"pip_name\": [\"torch\", \"torchvision\", \"torchaudio\"], \"import_name\": \"torch\"},\n",
    "    {\"name\": \"Keras\", \"pip_name\": \"keras\", \"import_name\": \"keras\"},\n",
    "    {\"name\": \"Hugging Face Transformers\", \"pip_name\": \"transformers\", \"import_name\": \"transformers\"},\n",
    "    {\"name\": \"Fastai\", \"pip_name\": \"fastai\", \"import_name\": \"fastai\"},\n",
    "    {\"name\": \"TPOT\", \"pip_name\": \"tpot\", \"import_name\": \"tpot\"},\n",
    "    {\"name\": \"MLflow\", \"pip_name\": \"mlflow\", \"import_name\": \"mlflow\"},\n",
    "\n",
    "    # ðŸ§ª Notebook Environment\n",
    "    {\"name\": \"JupyterLab\", \"pip_name\": \"jupyterlab\", \"import_name\": \"jupyterlab\"},\n",
    "    {\"name\": \"Notebook\", \"pip_name\": \"notebook\", \"import_name\": \"notebook\"},\n",
    "    {\"name\": \"Voila\", \"pip_name\": \"voila\", \"import_name\": \"voila\"},\n",
    "    \n",
    "]\n",
    "\n",
    "install_libs(ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4186f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… XGBoost already installed\n",
      "âœ… LightGBM already installed\n"
     ]
    }
   ],
   "source": [
    "ml2 = [\n",
    "    # ðŸ¤– Machine Learning 2\n",
    "    {\"name\": \"XGBoost\", \"pip_name\": \"xgboost\", \"import_name\": \"xgboost\"},\n",
    "    {\"name\": \"LightGBM\", \"pip_name\": \"lightgbm\", \"import_name\": \"lightgbm\"},\n",
    "    \n",
    "]\n",
    "\n",
    "install_libs(ml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f1f4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall xgboost -y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
