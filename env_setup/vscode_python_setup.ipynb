{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d1984a8",
   "metadata": {},
   "source": [
    "# Auto install python libraries for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c7c68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7294ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_libs(packages):\n",
    "    for package in packages:\n",
    "        try:\n",
    "            __import__(package[\"import_name\"])\n",
    "            print(f\"‚úÖ {package['name']} already installed\")\n",
    "        except ImportError:\n",
    "            print(f\"‚¨áÔ∏è Installing {package['name']}...\")\n",
    "\n",
    "            # ‚úÖ Handle both string and list pip_name\n",
    "            pip_args = package[\"pip_name\"]\n",
    "            if isinstance(pip_args, str):\n",
    "                pip_args = [pip_args]\n",
    "\n",
    "            try:\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pip_args])\n",
    "                print(f\"‚úÖ {package['name']} installed\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Failed to install {package['name']}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dabece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.1.1\n",
      "‚úÖ pip upgraded successfully.\n"
     ]
    }
   ],
   "source": [
    "def upgrade_pip():\n",
    "    \"\"\"\n",
    "    Upgrade pip to the latest version using subprocess.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"pip\"])\n",
    "        print(\"‚úÖ pip upgraded successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to upgrade pip: {e}\")\n",
    "\n",
    "\n",
    "upgrade_pip() #upgrade pip first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bb83c",
   "metadata": {},
   "source": [
    "# Mac specific pre-setup by installing require brew packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc9945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ unixodbc is already installed.\n",
      "‚úÖ snowflake is already installed.\n",
      "‚úÖ libomp is already installed.\n",
      "‚úÖ cmake is already installed.\n",
      "‚úÖ llvm is already installed.\n",
      "‚úÖ openssl@3 is already installed.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import platform\n",
    "\n",
    "def is_brew_available():\n",
    "    return shutil.which(\"brew\") is not None\n",
    "\n",
    "def is_package_installed(package):\n",
    "    result = subprocess.run([\"brew\", \"list\", \"--formula\", package], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "    return result.returncode == 0\n",
    "\n",
    "def brew_install(packages):\n",
    "    if not is_brew_available():\n",
    "        print(\"‚ùå Homebrew is not available in PATH.\")\n",
    "        return\n",
    "\n",
    "    for package in packages:\n",
    "        if is_package_installed(package):\n",
    "            print(f\"‚úÖ {package} is already installed.\")\n",
    "        else:\n",
    "            print(f\"‚¨áÔ∏è Installing {package}...\")\n",
    "            try:\n",
    "                subprocess.check_call([\"brew\", \"install\", package])\n",
    "                print(f\"‚úÖ {package} installed successfully.\\n\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Failed to install {package}: {e}\\n\")\n",
    "\n",
    "# brew packages to install\n",
    "libs = [\"unixodbc\", # ODBC driver for Snowflake\n",
    "        \"snowflake\", # Snowflake CLI\n",
    "        \"libomp\", # OpenMP support for XGBoost & LightGBM\n",
    "        'cmake', # CMake build system\n",
    "        \"llvm\", # Modern compiler toolchain used by some ML libraries\n",
    "        'openssl@3', # OpenSSL 3.x for compatibility\n",
    "        ]\n",
    "\n",
    "\n",
    "# Brew install if on macOS\n",
    "if platform.system() == 'Darwin':  # macOS returns 'Darwin'\n",
    "    brew_install(libs)\n",
    "else:\n",
    "    print(\"Not on macOS, skipping brew install\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da0075",
   "metadata": {},
   "source": [
    "# Data Science Libraries\n",
    "## 1. Data Wraggling Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e027c652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Pandas already installed\n",
      "‚úÖ Polars already installed\n",
      "‚úÖ Dask already installed\n",
      "‚úÖ PyArrow already installed\n",
      "‚úÖ PyTables already installed\n",
      "‚úÖ Feather already installed\n",
      "‚úÖ Parquet already installed\n",
      "‚úÖ HDF5 already installed\n",
      "‚úÖ CSV already installed\n",
      "‚úÖ JSON already installed\n",
      "‚úÖ Excel already installed\n",
      "‚úÖ HDF5 already installed\n"
     ]
    }
   ],
   "source": [
    "dw = [\n",
    "    # ‚úÖ Data Wrangling\n",
    "    {\"name\": \"Pandas\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"Polars\", \"pip_name\": \"polars\", \"import_name\": \"polars\"},\n",
    "    {\"name\": \"Dask\", \"pip_name\": \"dask[dataframe]\", \"import_name\": \"dask\"},\n",
    "    {\"name\": \"PyArrow\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow\"},\n",
    "    {\"name\": \"PyTables\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "    {\"name\": \"Feather\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow.feather\"},\n",
    "    {\"name\": \"Parquet\", \"pip_name\": \"pyarrow\", \"import_name\": \"pyarrow.parquet\"},\n",
    "    {\"name\": \"HDF5\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "    {\"name\": \"CSV\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"JSON\", \"pip_name\": \"pandas\", \"import_name\": \"pandas\"},\n",
    "    {\"name\": \"Excel\", \"pip_name\": \"openpyxl\", \"import_name\": \"openpyxl\"},\n",
    "    {\"name\": \"HDF5\", \"pip_name\": \"tables\", \"import_name\": \"tables\"},\n",
    "]\n",
    "\n",
    "install_libs(dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c3aab",
   "metadata": {},
   "source": [
    "## 2. Data Connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "072d7829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SQLAlchemy already installed\n",
      "‚úÖ PyODBC already installed\n",
      "‚úÖ psycopg2 (PostgreSQL) already installed\n",
      "‚úÖ MySQL Connector already installed\n",
      "‚úÖ MongoDB already installed\n",
      "‚úÖ SQLite already installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (20.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Snowflake Connector already installed\n",
      "‚úÖ Google BigQuery already installed\n",
      "‚úÖ AWS SDK (boto3) already installed\n",
      "‚úÖ Azure SDK already installed\n",
      "‚úÖ Databricks SQL Connector already installed\n",
      "‚úÖ Apache Kafka already installed\n",
      "‚úÖ Office365-REST-Python-Client already installed\n",
      "‚úÖ Tableau Hyper API already installed\n",
      "‚úÖ Power BI REST Client already installed\n",
      "‚úÖ Requests already installed\n",
      "‚úÖ HTTPX already installed\n",
      "‚úÖ FastAPI already installed\n",
      "‚úÖ Uvicorn (for FastAPI) already installed\n",
      "‚úÖ Flask already installed\n",
      "‚úÖ Django already installed\n",
      "‚úÖ Tornado already installed\n"
     ]
    }
   ],
   "source": [
    "dc = [\n",
    "    # üîå Data Connections ‚Äì Databases\n",
    "    {\"name\": \"SQLAlchemy\", \"pip_name\": \"sqlalchemy\", \"import_name\": \"sqlalchemy\"},\n",
    "    {\"name\": \"PyODBC\", \"pip_name\": \"pyodbc\", \"import_name\": \"pyodbc\"},\n",
    "    {\"name\": \"psycopg2 (PostgreSQL)\", \"pip_name\": \"psycopg2-binary\", \"import_name\": \"psycopg2\"},\n",
    "    {\"name\": \"MySQL Connector\", \"pip_name\": \"mysql-connector-python\", \"import_name\": \"mysql.connector\"},\n",
    "    {\"name\": \"MongoDB\", \"pip_name\": \"pymongo\", \"import_name\": \"pymongo\"},\n",
    "    {\"name\": \"SQLite\", \"pip_name\": \"sqlite3\", \"import_name\": \"sqlite3\"},\n",
    "\n",
    "    # üîå Data Connections ‚Äì Cloud\n",
    "    {\"name\": \"Snowflake Connector\", \"pip_name\": \"snowflake-connector-python\", \"import_name\": \"snowflake.connector\"},\n",
    "    {\"name\": \"Google BigQuery\", \"pip_name\": \"google-cloud-bigquery\", \"import_name\": \"google.cloud.bigquery\"},\n",
    "    {\"name\": \"AWS SDK (boto3)\", \"pip_name\": \"boto3\", \"import_name\": \"boto3\"},\n",
    "    {\"name\": \"Azure SDK\", \"pip_name\": \"azure-storage-blob\", \"import_name\": \"azure.storage.blob\"},\n",
    "    {\"name\": \"Databricks SQL Connector\", \"pip_name\": \"databricks-sql-connector\", \"import_name\": \"databricks.sql\"},\n",
    "    {\"name\": \"Apache Kafka\", \"pip_name\": \"kafka-python\", \"import_name\": \"kafka\"},\n",
    "\n",
    "    # üìÇ Microsoft SharePoint (via Office365 REST API)\n",
    "    {\"name\": \"Office365-REST-Python-Client\", \"pip_name\": \"Office365-REST-Python-Client\", \"import_name\": \"office365.sharepoint.client_context\"},\n",
    "\n",
    "    # üìä Tableau / Power BI Integration\n",
    "    {\"name\": \"Tableau Hyper API\", \"pip_name\": \"tableauhyperapi\", \"import_name\": \"tableauhyperapi\"},\n",
    "    {\"name\": \"Power BI REST Client\", \"pip_name\": \"powerbiclient\", \"import_name\": \"powerbiclient\"},\n",
    "\n",
    "    # üåê API Libraries\n",
    "    {\"name\": \"Requests\", \"pip_name\": \"requests\", \"import_name\": \"requests\"},\n",
    "    {\"name\": \"HTTPX\", \"pip_name\": \"httpx\", \"import_name\": \"httpx\"},\n",
    "    {\"name\": \"FastAPI\", \"pip_name\": \"fastapi\", \"import_name\": \"fastapi\"},\n",
    "    {\"name\": \"Uvicorn (for FastAPI)\", \"pip_name\": \"uvicorn\", \"import_name\": \"uvicorn\"},\n",
    "    {\"name\": \"Flask\", \"pip_name\": \"flask\", \"import_name\": \"flask\"},\n",
    "    {\"name\": \"Django\", \"pip_name\": \"django\", \"import_name\": \"django\"},\n",
    "    {\"name\": \"Tornado\", \"pip_name\": \"tornado\", \"import_name\": \"tornado\"},\n",
    "]\n",
    "\n",
    "install_libs(dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d49061",
   "metadata": {},
   "source": [
    "## 3. Stat and Visualization Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79182f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Whoosh already installed\n",
      "‚úÖ NLTK already installed\n",
      "‚úÖ spaCy already installed\n",
      "‚úÖ TextBlob already installed\n",
      "‚¨áÔ∏è Installing Gensim...\n",
      "Collecting gensim\n",
      "  Using cached gensim-4.3.3.tar.gz (23.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Using cached scipy-1.13.1.tar.gz (57.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[54 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-vcb2bj6t/scipy_4fbb9db18e634f3ea774030f83751e1b /private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-vcb2bj6t/scipy_4fbb9db18e634f3ea774030f83751e1b/.mesonpy-15u76ox0 -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-vcb2bj6t/scipy_4fbb9db18e634f3ea774030f83751e1b/.mesonpy-15u76ox0/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.8.2\n",
      "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-vcb2bj6t/scipy_4fbb9db18e634f3ea774030f83751e1b\n",
      "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-vcb2bj6t/scipy_4fbb9db18e634f3ea774030f83751e1b/.mesonpy-15u76ox0\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: scipy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.13.1\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (clang 17.0.0 \"Apple clang version 17.0.0 (clang-1700.0.13.5)\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 3.0.12)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: aarch64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: aarch64\n",
      "  \u001b[31m   \u001b[0m Program python found: YES (/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/bin/python)\n",
      "  \u001b[31m   \u001b[0m Did not find pkg-config by name 'pkg-config'\n",
      "  \u001b[31m   \u001b[0m Found pkg-config: NO\n",
      "  \u001b[31m   \u001b[0m Run-time dependency python found: YES 3.13\n",
      "  \u001b[31m   \u001b[0m Program cython found: YES (/private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-build-env-7tjedmoa/overlay/bin/cython)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../meson.build:78:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang-new'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['ifx'], ['g95']]\n",
      "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --help` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --version` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran -V` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --help` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --version` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new -V` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --help` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --version` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang -V` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --help` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --version` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran -V` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --help` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --version` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran -V` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --help` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --version` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort -V` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --help` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --version` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx -V` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --help` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --version` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 -V` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-vcb2bj6t/scipy_4fbb9db18e634f3ea774030f83751e1b/.mesonpy-15u76ox0/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to install Gensim: Command '['/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/bin/python', '-m', 'pip', 'install', 'gensim']' returned non-zero exit status 1.\n",
      "‚¨áÔ∏è Installing DataExplorer...\n",
      "Requirement already satisfied: dataexplorer in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (1.0.1)\n",
      "Requirement already satisfied: numpy in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataexplorer) (2.3.0)\n",
      "Requirement already satisfied: pandas in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataexplorer) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas->dataexplorer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas->dataexplorer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas->dataexplorer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->dataexplorer) (1.17.0)\n",
      "‚úÖ DataExplorer installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages/dataprofiler/labelers/base_data_labeler.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Installing DataProfiler...\n",
      "Requirement already satisfied: dataprofiler in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (0.13.3)\n",
      "Requirement already satisfied: h5py>=2.10.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (3.14.0)\n",
      "Requirement already satisfied: wheel>=0.33.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (0.45.1)\n",
      "Collecting numpy<2.0.0 (from dataprofiler)\n",
      "  Using cached numpy-1.26.4-cp313-cp313-macosx_15_0_arm64.whl\n",
      "Requirement already satisfied: pandas>=1.1.2 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.5 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=1.0.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (20.0.0)\n",
      "Requirement already satisfied: chardet>=3.0.4 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (5.2.0)\n",
      "Requirement already satisfied: fastavro>=1.1.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (1.11.1)\n",
      "Requirement already satisfied: python-snappy>=0.7.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (0.7.3)\n",
      "Requirement already satisfied: charset-normalizer>=1.3.6 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (3.4.2)\n",
      "Requirement already satisfied: psutil>=4.0.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (7.0.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (1.15.3)\n",
      "Requirement already satisfied: requests==2.32.* in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (2.32.4)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (3.5)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.2 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (4.14.0)\n",
      "Requirement already satisfied: HLL>=2.0.3 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (2.3.0)\n",
      "Requirement already satisfied: datasketches>=4.1.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (5.2.0)\n",
      "Requirement already satisfied: packaging>=23.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (25.0)\n",
      "Requirement already satisfied: boto3>=1.28.61 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (1.38.36)\n",
      "Requirement already satisfied: versioneer in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from dataprofiler) (0.29)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from requests==2.32.*->dataprofiler) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from requests==2.32.*->dataprofiler) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from requests==2.32.*->dataprofiler) (2025.6.15)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.36 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from boto3>=1.28.61->dataprofiler) (1.38.36)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from boto3>=1.28.61->dataprofiler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from boto3>=1.28.61->dataprofiler) (0.13.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from python-dateutil>=2.7.5->dataprofiler) (1.17.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas>=1.1.2->dataprofiler) (2025.2)\n",
      "Requirement already satisfied: cramjam in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from python-snappy>=0.7.1->dataprofiler) (2.10.0)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.0\n",
      "    Uninstalling numpy-2.3.0:\n",
      "      Successfully uninstalled numpy-2.3.0\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ml-dtypes 0.5.1 requires numpy>=2.1.0; python_version >= \"3.13\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ DataProfiler installed\n",
      "‚úÖ Autoviz already installed\n",
      "‚¨áÔ∏è Installing Pandas Profiling...\n",
      "Collecting pandas-profiling\n",
      "  Using cached pandas_profiling-3.2.0-py2.py3-none-any.whl.metadata (21 kB)\n",
      "Collecting joblib~=1.1.0 (from pandas-profiling)\n",
      "  Using cached joblib-1.1.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (1.15.3)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (2.2.3)\n",
      "Requirement already satisfied: matplotlib>=3.2.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (3.10.3)\n",
      "Requirement already satisfied: pydantic>=1.8.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (2.11.7)\n",
      "Requirement already satisfied: PyYAML>=5.0.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (6.0.2)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (3.1.6)\n",
      "Collecting markupsafe~=2.1.1 (from pandas-profiling)\n",
      "  Using cached MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting visions==0.7.4 (from visions[type_image_path]==0.7.4->pandas-profiling)\n",
      "  Using cached visions-0.7.4-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from pandas-profiling) (1.26.4)\n",
      "Collecting htmlmin>=0.1.12 (from pandas-profiling)\n",
      "  Using cached htmlmin-0.1.12.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m \u001b[31m[19 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m2\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31mexec\u001b[0m\u001b[1;31m(compile('''\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m# This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     ...<32 lines>...\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31mexec(compile(setup_py_code, filename, \"exec\"))\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m''' % ('/private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-8xb97fq9/htmlmin_ac4e7bd322b248c7857767d52804177b/setup.py',), \"<pip-setuptools-caller>\", \"exec\"))\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"<pip-setuptools-caller>\"\u001b[0m, line \u001b[35m35\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-8xb97fq9/htmlmin_ac4e7bd322b248c7857767d52804177b/setup.py\"\u001b[0m, line \u001b[35m4\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     from htmlmin import __version__\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-8xb97fq9/htmlmin_ac4e7bd322b248c7857767d52804177b/htmlmin/__init__.py\"\u001b[0m, line \u001b[35m28\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     from .main import minify, Minifier\n",
      "  \u001b[31m   \u001b[0m   File \u001b[35m\"/private/var/folders/z0/fnx5vqm50lgchltnb7sh25680000gq/T/pip-install-8xb97fq9/htmlmin_ac4e7bd322b248c7857767d52804177b/htmlmin/main.py\"\u001b[0m, line \u001b[35m28\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[31m   \u001b[0m     import cgi\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'cgi'\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to install Pandas Profiling: Command '['/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/bin/python', '-m', 'pip', 'install', 'pandas-profiling']' returned non-zero exit status 1.\n",
      "‚¨áÔ∏è Installing YData Profiling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Ignored the following versions that require a different python version: 4.0.0 Requires-Python >=3.7, <3.11; 4.1.0 Requires-Python >=3.7, <3.12; 4.1.1 Requires-Python >=3.7, <3.12; 4.1.2 Requires-Python >=3.7, <3.12; 4.10.0 Requires-Python <3.13,>=3.7; 4.11.0 Requires-Python <3.13,>=3.7; 4.12.0 Requires-Python <3.13,>=3.7; 4.12.1 Requires-Python <3.13,>=3.7; 4.12.2 Requires-Python <3.13,>=3.7; 4.13.0 Requires-Python <3.13,>=3.7; 4.14.0 Requires-Python <3.13,>=3.7; 4.15.0 Requires-Python <3.13,>=3.7; 4.15.1 Requires-Python <3.13,>=3.7; 4.16.0 Requires-Python <3.13,>=3.7; 4.16.1 Requires-Python <3.13,>=3.7; 4.2.0 Requires-Python >=3.7, <3.12; 4.3.0 Requires-Python >=3.7, <3.12; 4.3.1 Requires-Python >=3.7, <3.12; 4.3.2 Requires-Python >=3.7, <3.12; 4.4.0 Requires-Python >=3.7, <3.12; 4.5.0 Requires-Python >=3.7, <3.12; 4.5.1 Requires-Python >=3.7, <3.12; 4.6.0 Requires-Python >=3.7, <3.12; 4.6.1 Requires-Python >=3.7, <3.12; 4.6.2 Requires-Python >=3.7, <3.12; 4.6.3 Requires-Python >=3.7, <3.12; 4.6.4 Requires-Python >=3.7, <3.12; 4.6.5 Requires-Python >=3.7, <3.12; 4.7.0 Requires-Python >=3.7, <3.13; 4.8.3 Requires-Python <3.13,>=3.7; 4.9.0 Requires-Python <3.13,>=3.7\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement ydata-profiling (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for ydata-profiling\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to install YData Profiling: Command '['/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/bin/python', '-m', 'pip', 'install', 'ydata-profiling']' returned non-zero exit status 1.\n",
      "‚úÖ Sweetviz already installed\n",
      "‚¨áÔ∏è Installing D-Tale...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement d-tale (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for d-tale\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Failed to install D-Tale: Command '['/Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/bin/python', '-m', 'pip', 'install', 'd-tale']' returned non-zero exit status 1.\n",
      "‚úÖ NumPy already installed\n",
      "‚úÖ SciPy already installed\n",
      "‚úÖ Statsmodels already installed\n",
      "‚úÖ Matplotlib already installed\n",
      "‚úÖ Seaborn already installed\n",
      "‚úÖ Plotly already installed\n",
      "‚úÖ Altair already installed\n",
      "‚úÖ Bokeh already installed\n",
      "‚úÖ Geopandas already installed\n"
     ]
    }
   ],
   "source": [
    "sv = [\n",
    "    # üîç Search & Text Processing\n",
    "    {\"name\": \"Whoosh\", \"pip_name\": \"whoosh\", \"import_name\": \"whoosh\"},\n",
    "    {\"name\": \"NLTK\", \"pip_name\": \"nltk\", \"import_name\": \"nltk\"},\n",
    "    {\"name\": \"spaCy\", \"pip_name\": \"spacy\", \"import_name\": \"spacy\"},\n",
    "    {\"name\": \"TextBlob\", \"pip_name\": \"textblob\", \"import_name\": \"textblob\"},\n",
    "    {\"name\": \"Gensim\", \"pip_name\": \"gensim\", \"import_name\": \"gensim\"},\n",
    "\n",
    "    # üß≠ Data exploration and profiling\n",
    "    {\"name\": \"DataExplorer\", \"pip_name\": \"dataexplorer\", \"import_name\": \"dataexplorer\"},\n",
    "    {\"name\": \"DataProfiler\", \"pip_name\": \"dataprofiler\", \"import_name\": \"dataprofiler\"},\n",
    "    {\"name\": \"Autoviz\", \"pip_name\": \"autovizwidget\", \"import_name\": \"autovizwidget\"},\n",
    "    {\"name\": \"Pandas Profiling\", \"pip_name\": \"pandas-profiling\", \"import_name\": \"pandas_profiling\"},\n",
    "    {\"name\": \"YData Profiling\", \"pip_name\": \"ydata-profiling\", \"import_name\": \"ydata_profiling\"},\n",
    "    {\"name\": \"Sweetviz\", \"pip_name\": \"sweetviz\", \"import_name\": \"sweetviz\"},\n",
    "    {\"name\": \"D-Tale\", \"pip_name\": \"d-tale\", \"import_name\": \"dtale\"},\n",
    "\n",
    "    # üìä Statistics & Math\n",
    "    {\"name\": \"NumPy\", \"pip_name\": \"numpy\", \"import_name\": \"numpy\"},\n",
    "    {\"name\": \"SciPy\", \"pip_name\": \"scipy\", \"import_name\": \"scipy\"},\n",
    "    {\"name\": \"Statsmodels\", \"pip_name\": \"statsmodels\", \"import_name\": \"statsmodels\"},\n",
    "\n",
    "    # üìà Visualization\n",
    "    {\"name\": \"Matplotlib\", \"pip_name\": \"matplotlib\", \"import_name\": \"matplotlib\"},\n",
    "    {\"name\": \"Seaborn\", \"pip_name\": \"seaborn\", \"import_name\": \"seaborn\"},\n",
    "    {\"name\": \"Plotly\", \"pip_name\": \"plotly\", \"import_name\": \"plotly\"},\n",
    "    {\"name\": \"Altair\", \"pip_name\": \"altair\", \"import_name\": \"altair\"},\n",
    "    {\"name\": \"Bokeh\", \"pip_name\": \"bokeh\", \"import_name\": \"bokeh\"},\n",
    "    {\"name\": \"Geopandas\", \"pip_name\": \"geopandas\", \"import_name\": \"geopandas\"},\n",
    "]\n",
    "\n",
    "install_libs(sv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64072369",
   "metadata": {},
   "source": [
    "## 4. ML and Other Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f93ba05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scikit-learn already installed\n",
      "‚úÖ CatBoost already installed\n",
      "‚úÖ Category Encoders already installed\n",
      "‚úÖ PyTorch already installed\n",
      "‚¨áÔ∏è Installing Keras...\n",
      "Requirement already satisfied: keras in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (2.3.0)\n",
      "Requirement already satisfied: numpy in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from keras) (25.0)\n",
      "Collecting numpy (from keras)\n",
      "  Using cached numpy-2.3.0-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from optree->keras) (4.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nhan.tran/Library/CloudStorage/OneDrive-Interpublic/Documents/GitHub/andis-all-stars/Nhan/env/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Using cached numpy-2.3.0-cp313-cp313-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dataprofiler 0.13.3 requires numpy<2.0.0, but you have numpy 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed numpy-2.3.0\n",
      "‚úÖ Keras installed\n",
      "‚úÖ Hugging Face Transformers already installed\n",
      "‚úÖ Fastai already installed\n",
      "‚úÖ TPOT already installed\n",
      "‚úÖ MLflow already installed\n",
      "‚úÖ JupyterLab already installed\n",
      "‚úÖ Notebook already installed\n",
      "‚úÖ Voila already installed\n"
     ]
    }
   ],
   "source": [
    "# Define required packages\n",
    "import os\n",
    "os.environ[\"DYLD_LIBRARY_PATH\"] = \"/opt/homebrew/opt/libomp/lib\"\n",
    "\n",
    "ml = [\n",
    "    # ü§ñ Machine Learning\n",
    "    {\"name\": \"Scikit-learn\", \"pip_name\": \"scikit-learn\", \"import_name\": \"sklearn\"},\n",
    "    {\"name\": \"CatBoost\", \"pip_name\": \"catboost\", \"import_name\": \"catboost\"},\n",
    "    {\"name\": \"Category Encoders\", \"pip_name\": \"category_encoders\", \"import_name\": \"category_encoders\"},\n",
    "    {\"name\": \"PyTorch\", \"pip_name\": [\"torch\", \"torchvision\", \"torchaudio\"], \"import_name\": \"torch\"},\n",
    "    {\"name\": \"Keras\", \"pip_name\": \"keras\", \"import_name\": \"keras\"},\n",
    "    {\"name\": \"Hugging Face Transformers\", \"pip_name\": \"transformers\", \"import_name\": \"transformers\"},\n",
    "    {\"name\": \"Fastai\", \"pip_name\": \"fastai\", \"import_name\": \"fastai\"},\n",
    "    {\"name\": \"TPOT\", \"pip_name\": \"tpot\", \"import_name\": \"tpot\"},\n",
    "    {\"name\": \"MLflow\", \"pip_name\": \"mlflow\", \"import_name\": \"mlflow\"},\n",
    "\n",
    "    # üß™ Notebook Environment\n",
    "    {\"name\": \"JupyterLab\", \"pip_name\": \"jupyterlab\", \"import_name\": \"jupyterlab\"},\n",
    "    {\"name\": \"Notebook\", \"pip_name\": \"notebook\", \"import_name\": \"notebook\"},\n",
    "    {\"name\": \"Voila\", \"pip_name\": \"voila\", \"import_name\": \"voila\"},\n",
    "    \n",
    "]\n",
    "\n",
    "install_libs(ml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4186f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ XGBoost already installed\n",
      "‚úÖ LightGBM already installed\n"
     ]
    }
   ],
   "source": [
    "ml2 = [\n",
    "    # ü§ñ Machine Learning 2 - separating out these bc they tend to encounter trouble when installing\n",
    "    {\"name\": \"XGBoost\", \"pip_name\": \"xgboost\", \"import_name\": \"xgboost\"},\n",
    "    {\"name\": \"LightGBM\", \"pip_name\": \"lightgbm\", \"import_name\": \"lightgbm\"},\n",
    "    # {\"name\": \"TensorFlow\", \"pip_name\": \"tensorflow\", \"import_name\": \"tensorflow\"},\n",
    "    ]\n",
    "\n",
    "install_libs(ml2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f1f4898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall xgboost -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ee15e",
   "metadata": {},
   "source": [
    "# Pip Upgrade all Lib (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "def upgrade_all_packages():\n",
    "    \"\"\"\n",
    "    Upgrade all installed pip packages to their latest version.\n",
    "    \"\"\"\n",
    "    print(\"üîç Collecting installed packages...\")\n",
    "    packages = [dist.project_name for dist in pkg_resources.working_set]\n",
    "    \n",
    "    print(\"üöÄ Upgrading packages...\")\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])\n",
    "            print(f\"‚úÖ Upgraded: {package}\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to upgrade {package}: {e}\")\n",
    "\n",
    "# upgrade_all_packages()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
